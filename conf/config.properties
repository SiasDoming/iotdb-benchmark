######################################################
#################### IoTDB参数配置 ####################
######################################################
########## IoTDB通用配置 ##########
# 数据库的版本,自动填充HEAD的commit id,仅作标识使用
VERSION=0.12.0-SNAPSHOT
# 是否启用thrift的压缩机制
ENABLE_THRIFT_COMPRESSION=false
# 是否使用IoTDB集群模式
USE_CLUSTER_DB=false
########## 单节点IoTDB连接配置 ##########
# JDBC HOST and PORT
# IoTDB Default PORT: 6667
HOST=127.0.0.1
PORT=6667
########## IoTDB集群连接配置 ##########
# IoTDB集群服务器HOST和PORT
CLUSTER_HOSTS=127.0.0.1:55560,127.0.0.1:55561,127.0.0.1:55562


#################################################################
#################### Benchmark测试通用参数配置 ####################
#################################################################
# benchmark运行模式
# 目前支持多种运行模式，分别为：
# testWithDefaultPath--常规测试模式，支持多种读和写操作的混合负载
# serverMODE--服务器资源使用监控模式（该模式推荐通过ser-benchmark.sh脚本启动，无需手动配置该参数），需要配置 DB_DATA_PATH, INTERVAL 以及 NET_DEVICE
# importDataFromCSV--从CSV文件中读取数据模式，需要配置 IMPORT_DATA_FILE_PATH, METADATA_FILE_PATH 以及 BATCH_EXECUTE_COUNT
BENCHMARK_WORK_MODE=testWithDefaultPath
# 各操作的执行次数,按照顺序 W1:Q1:Q2:Q3 （请注意使用英文冒号，比例中的每一项是整数）
# W1--数据写入（只适用于自动生成数据集） insert into data (timestamp, s1, s2...) values (t1, v11, v21..., t2, v12, v22..., ...)
# Q1--范围查询（只限制起止时间）select v1... from data where time > ? and time < ? and device in ?
# Q2--带时间过滤的聚合查询 select func(v1)... from data where device in ? and time > ? and time < ?
# Q3--带时间过滤的UDF查询 select udf_func(v1)... from data where device in ? and time > ? and time < ?
OPERATION_PROPORTION=1000:1000:1000:1000
# 以上操作循环执行的重复次数
LOOP=1
# 相邻操作的执行间隔, 若当前操作耗时大于该间隔则马上执行下一个操作，否则等待 (OP_INTERVAL-实际执行时间) ms
OP_INTERVAL=0
# 测试完成后是否清除旧数据(是否执行cleanup)，包括以下两个操作
# 删除数据 DELETE TIMESERIES root.GROUP_NAME_PREFIX*
# 卸载已注册的UDF DROP FUNCTION UDFNameList
IS_DELETE_DATA=false
# 客户端并发数
CLIENT_NUMBER=1
# 并行客户端和设备是否绑定
# 若客户端和设备绑定，则必须小于等于设备数
# 否则客户端数可以大于设备数
IS_CLIENT_BIND=true
# 测试阶段输出进度日志的时间间隔/s
LOG_PRINT_INTERVAL=5
# 是否静默运行，屏蔽部分日志输出
IS_QUIET_MODE=true


########################################################
#################### 写入测试参数配置 ####################
########################################################
########## 通用参数 ##########
# IoTDB数据写入方式，支持 jdbc, sessionByRecord, sessionByRecords, sessionByTablet
INSERT_MODE=sessionByTablet
# 存储组数，必须小于等于设备数
GROUP_NUMBER=1
# 存储组名称前缀，如果GROUP_NUMBER=3，则默认生成3个如下存储组：root.group_0、root.group_1、root.group_2
GROUP_NAME_PREFIX=group_
# device对应storage group的分配策略
# hash 表示device通过hash的方式分配到存储组中
# mod 表示device通过对存储组数取模的方式平均分配到存储组中（相邻编号device分散在不同存储组中）
# div 表示device通过对存储组数取商的方式分配到存储组中（相邻编号device集中在相同存储组中）
SG_STRATEGY=mod
# 是否写入前先创建schema
CREATE_SCHEMA=true
# 批写入数据行数，每行是某个设备所有传感器在某一时间戳的数据，每个batch写入数据点数=SENSOR_NUMBER*BATCH_SIZE
BATCH_SIZE=1000
# workload预生成数值的缓存大小
WORKLOAD_BUFFER_SIZE=100
########## 合成数据集数据量配置 ##########
# 总设备数
DEVICE_NUMBER=10
# 实际进行写入的设备数占全部设备的比例, 取值范围(0, 1]
REAL_INSERT_RATE=1.0
# 每个设备的传感器数，总时间序列条数=DEVICE_NUMBER*SENSOR_NUMBER
SENSOR_NUMBER=6
# 合成数据起始时间
START_TIME=2020-1-1T00:00:00+08:00
# 时间戳精度（包含ms(毫秒)和us(微秒)两种，主要应用于时间戳）
TIMESTAMP_PRECISION=ms
# 时间戳间隔（非真实速率，大致对应为POINT_STEP*TIMESTAMP_PRECISION时长生成一个数据点）
POINT_STEP=1000
########## 生成数据点时间戳顺序 ##########
# 是否为乱序插入模式
IS_OVERFLOW=false
# 支持多种乱序模式:
# 0--按泊松分布的乱序模式
# 1--批插入乱序模式
OVERFLOW_MODE=0
# 批插入乱序比例，该参数取值范围(0,1)
OVERFLOW_RATIO=0.5
# Poisson Distribution Related in overflow mode 0
# the expectation and variance of Poisson Distribution based on basic model
LAMBDA=2200.0
# the max K of Poisson random variable based on basic model
MAX_K=170000
# 是否在顺序数据中使用随机时间间隔,若这一参数为true时需要IS_OVERFLOW=false
IS_RANDOM_TIMESTAMP_INTERVAL=false
########## 生成数据类型 ##########
# 插入时各数据类型的比例，类似操作比例，注意使用英文冒号
# T1:T2:T3:T4:T5:T6
# T1--BOOLEAN
# T2--INT32
# T3--INT64
# T4--FLOAT
# T5--DOUBLE
# T6--TEXT
INSERT_DATATYPE_PROPORTION=1:1:1:1:1:1
# 各数据类型的编码方式
# BOOLEAN: PLAIN/RLE
ENCODING_BOOLEAN=PLAIN
# INT32: PLAIN/RLE/TS_2DIFF/REGULAR
ENCODING_INT32=PLAIN
# INT64: PLAIN/RLE/TS_2DIFF/REGULAR
ENCODING_INT64=PLAIN
# FLOAT: PLAIN/RLE/TS_2DIFF/GORILLA
ENCODING_FLOAT=PLAIN
# DOUBLE: PLAIN/RLE/TS_2DIFF/GORILLA
ENCODING_DOUBLE=PLAIN
# TEXT: PLAIN
ENCODING_TEXT=PLAIN
# 生成数据的小数位数
NUMBER_OF_DECIMAL_DIGIT=3
# 压缩方式 UNCOMPRESSOR | SNAPPY
COMPRESSOR=SNAPPY
########## 数据生成函数配置 ##########
# 随机数生成器种子
DATA_SEED=666
# 不同生成函数被采用的比例
# 线性函数
LINE_RATIO=1
# sin正弦函数
SIN_RATIO=1
# 方波函数
SQUARE_RATIO=1
# 随机数函数
RANDOM_RATIO=1
# 常函数
CONSTANT_RATIO=1


########################################################
#################### 查询测试参数配置 ####################
########################################################
# 查询随机种子
QUERY_SEED=151658
# 每条查询语句中查询涉及的设备数量
QUERY_DEVICE_NUM=1
# 每条查询语句中查询涉及的传感器数量
# 每条查询语句实际涉及的时间序列数量为 QUERY_DEVICE_NUM * QUERY_SENSOR_NUM
# 注：对于涉及多条时间序列输入的UDF查询，QUERY_DEVICE_NUM * QUERY_SENSOR_NUM 对应于每条查询语句中执行UDF的次数
QUERY_SENSOR_NUM=1
# 带起止时间的查询中开始时间与结束时间之间的时间间隔
QUERY_INTERVAL=10000000000
# 合成数据查询不需要单独指定时间筛选起始时间，首次查询起始时间与合成数据起始时间START_TIME一致
# 相邻两次查询时间过滤条件的起点变化步长, 实际起点时间变化量为STEP_SIZE*POINT_STEP
STEP_SIZE=0
# 聚合查询使用的聚合函数名
QUERY_AGGREGATE_FUN=count
# 整个写操作的超时时间，即如果整个写操作在指定时间内没有返回，则终止此操作，单位毫秒
WRITE_OPERATION_TIMEOUT_MS=120000
# 整个读操作的超时时间，即如果整个读操作在指定时间内没有返回，则终止此操作，单位毫秒
READ_OPERATION_TIMEOUT_MS=300000


############################################################
#################### Server Mode环境配置 ####################
############################################################
# to do: 重命名该变量，符合终止监测的性质
# 监测状态文件目录, log_stop_flag是一个文件，用于停止benchmark的监控模式
MONITOR_FLAG_PATH=IOTDB_HOME/data
# IoTDB数据盘所在目录,可以是多目录,多目录间用逗号分割
IOTDB_DATA_DIR=IOTDB_HOME/data/data
# IoTDB写前日志WAL所在目录,可以是多目录,多目录间用逗号分割
IOTDB_WAL_DIR=IOTDB_HOME/data/wal
# IoTDB的system文件夹所在目录,可以是多目录,多目录间用逗号分割
IOTDB_SYSTEM_DIR=IOTDB_HOME/data/system
# 系统性能检测网卡设备名
NET_DEVICE=e
# INTERVAL=n表示系统信息记录间隔为n+2秒
INTERVAL=0


#############################################################
#################### 测试结果持久化参数配置 ####################
#############################################################
# 结果持久化写入数据库选择: None, IoTDB, MySQL
TEST_DATA_PERSISTENCE=None
# 测试结果持久化数据库连接参数
TEST_DATA_STORE_IP=166.111.7.145
TEST_DATA_STORE_PORT=6667
TEST_DATA_STORE_DB=test
TEST_DATA_STORE_USER=root
TEST_DATA_STORE_PW=root
# 对本次实验的备注，作为表名的一部分存入mysql中，注意不要有.等特殊字符
REMARK=
# 是否将结果输出至CSV文件
CSV_OUTPUT=true
